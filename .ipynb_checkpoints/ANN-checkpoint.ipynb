{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.linear_model import Perceptron\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)] # petal length, petal width \n",
    "y = (iris.target == 0).astype(np.int) # Iris setosa?\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)\n",
    "y_pred = per_clf.predict([[2, 0.5]])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.3.1', '2.4.0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.__version__, keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1489acb80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train_full[0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = dict(zip(class_names, np.arange(len(class_names))))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([ keras.layers.Flatten(input_shape=[28, 28]),\n",
    "                                 keras.layers.Dense(300, activation=\"relu\"),\n",
    "                                 keras.layers.Dense(100, activation=\"relu\"),\n",
    "                                 keras.layers.Dense(10, activation=\"softmax\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x1669806a0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x166980d90>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x166d426d0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x166d42940>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_9'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x166980d90>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.06325665,  0.04930412,  0.04498298, ...,  0.01680926,\n",
       "          0.06102946, -0.01515599],\n",
       "        [-0.07330325, -0.06625023, -0.03115141, ..., -0.0650421 ,\n",
       "          0.05585501,  0.03865632],\n",
       "        [-0.0358261 ,  0.00929799,  0.02096441, ..., -0.07121293,\n",
       "          0.00390845,  0.02510912],\n",
       "        ...,\n",
       "        [-0.01410369, -0.04696845, -0.01323918, ...,  0.05490254,\n",
       "         -0.06086296,  0.04912889],\n",
       "        [ 0.01110097,  0.00418211,  0.06592266, ..., -0.04195098,\n",
       "         -0.05403174,  0.05434726],\n",
       "        [-0.05875874,  0.00528944,  0.03158437, ...,  0.01185462,\n",
       "          0.05109103,  0.06711343]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = hidden.get_weights()\n",
    "weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.7327 - accuracy: 0.7571 - val_loss: 0.5054 - val_accuracy: 0.8366\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4938 - accuracy: 0.8285 - val_loss: 0.4536 - val_accuracy: 0.8466\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4484 - accuracy: 0.8436 - val_loss: 0.4319 - val_accuracy: 0.8528\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4204 - accuracy: 0.8535 - val_loss: 0.4169 - val_accuracy: 0.8562\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4000 - accuracy: 0.8592 - val_loss: 0.3991 - val_accuracy: 0.8604\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3853 - accuracy: 0.8646 - val_loss: 0.4097 - val_accuracy: 0.8516\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3716 - accuracy: 0.8678 - val_loss: 0.3810 - val_accuracy: 0.8662\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3592 - accuracy: 0.8733 - val_loss: 0.3629 - val_accuracy: 0.8684\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3493 - accuracy: 0.8754 - val_loss: 0.3620 - val_accuracy: 0.8722\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3408 - accuracy: 0.8791 - val_loss: 0.3449 - val_accuracy: 0.8810\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3313 - accuracy: 0.8824 - val_loss: 0.3463 - val_accuracy: 0.8760\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3242 - accuracy: 0.8844 - val_loss: 0.3489 - val_accuracy: 0.8762\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3162 - accuracy: 0.8866 - val_loss: 0.3267 - val_accuracy: 0.8820\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3089 - accuracy: 0.8888 - val_loss: 0.3258 - val_accuracy: 0.8846\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3020 - accuracy: 0.8910 - val_loss: 0.3335 - val_accuracy: 0.8798\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2949 - accuracy: 0.8945 - val_loss: 0.3246 - val_accuracy: 0.8822\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2886 - accuracy: 0.8969 - val_loss: 0.3579 - val_accuracy: 0.8642\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2849 - accuracy: 0.8972 - val_loss: 0.3128 - val_accuracy: 0.8862\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2792 - accuracy: 0.8991 - val_loss: 0.3126 - val_accuracy: 0.8844\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2742 - accuracy: 0.9003 - val_loss: 0.3155 - val_accuracy: 0.8832\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2699 - accuracy: 0.9016 - val_loss: 0.3216 - val_accuracy: 0.8844\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2651 - accuracy: 0.9041 - val_loss: 0.3087 - val_accuracy: 0.8908\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2595 - accuracy: 0.9055 - val_loss: 0.3149 - val_accuracy: 0.8880\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2549 - accuracy: 0.9081 - val_loss: 0.3120 - val_accuracy: 0.8876\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2502 - accuracy: 0.9094 - val_loss: 0.3101 - val_accuracy: 0.8900\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2459 - accuracy: 0.9112 - val_loss: 0.3119 - val_accuracy: 0.8854\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2429 - accuracy: 0.9121 - val_loss: 0.3255 - val_accuracy: 0.8846\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2400 - accuracy: 0.9139 - val_loss: 0.3090 - val_accuracy: 0.8898\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2349 - accuracy: 0.9156 - val_loss: 0.3026 - val_accuracy: 0.8906\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2312 - accuracy: 0.9173 - val_loss: 0.3014 - val_accuracy: 0.8934\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5)) \n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 62.0368 - accuracy: 0.8509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[62.036842346191406, 0.8508999943733215]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split( housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split( X_train_full, y_train_full)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train) \n",
    "X_valid = scaler.transform(X_valid) \n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 989us/step - loss: 0.7419 - val_loss: 0.5774\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 803us/step - loss: 0.5041 - val_loss: 0.5049\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 857us/step - loss: 0.6034 - val_loss: 0.6459\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 770us/step - loss: 0.4922 - val_loss: 0.5017\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 780us/step - loss: 0.4570 - val_loss: 0.4785\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 759us/step - loss: 0.4387 - val_loss: 0.4770\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 854us/step - loss: 0.4348 - val_loss: 0.4627\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 813us/step - loss: 0.4241 - val_loss: 0.4538\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 792us/step - loss: 0.4156 - val_loss: 0.4474\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 822us/step - loss: 0.4121 - val_loss: 0.4407\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 840us/step - loss: 0.4093 - val_loss: 0.4352\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 834us/step - loss: 0.4104 - val_loss: 0.4300\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 789us/step - loss: 0.3969 - val_loss: 0.4347\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 762us/step - loss: 0.3941 - val_loss: 0.4266\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 775us/step - loss: 0.3938 - val_loss: 0.4224\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 791us/step - loss: 0.4009 - val_loss: 0.4145\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 813us/step - loss: 0.3809 - val_loss: 0.4141\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 822us/step - loss: 0.3892 - val_loss: 0.4186\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 812us/step - loss: 0.3777 - val_loss: 0.4071\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 826us/step - loss: 0.3758 - val_loss: 0.4054\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "                                 keras.layers.Dense(1)])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 593us/step - loss: 0.4007\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.110326 ],\n",
       "        [2.5402265],\n",
       "        [3.6845734]], dtype=float32),\n",
       " array([1.008, 2.19 , 3.257]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred, y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 30)           270         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 30)           930         dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 38)           0           input_4[0][0]                    \n",
      "                                                                 dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1)            39          concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=(5), name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=(6), name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "deep_input (InputLayer)         [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 30)           210         deep_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "wide_input (InputLayer)         [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 30)           930         dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 35)           0           wide_input[0][0]                 \n",
      "                                                                 dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            36          concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,176\n",
      "Trainable params: 1,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.0656 - val_loss: 0.8470\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 965us/step - loss: 0.7136 - val_loss: 0.7152\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 940us/step - loss: 0.6289 - val_loss: 0.6699\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 927us/step - loss: 0.5946 - val_loss: 0.6397\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 881us/step - loss: 0.5702 - val_loss: 0.6156\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 877us/step - loss: 0.5508 - val_loss: 0.5950\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 879us/step - loss: 0.5357 - val_loss: 0.5789\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 953us/step - loss: 0.5242 - val_loss: 0.5664\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 888us/step - loss: 0.5149 - val_loss: 0.5552\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 890us/step - loss: 0.5070 - val_loss: 0.5454\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 953us/step - loss: 0.5010 - val_loss: 0.5383\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 871us/step - loss: 0.4953 - val_loss: 0.5319\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 893us/step - loss: 0.4905 - val_loss: 0.5252\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 919us/step - loss: 0.4858 - val_loss: 0.5207\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 900us/step - loss: 0.4822 - val_loss: 0.5162\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 893us/step - loss: 0.4783 - val_loss: 0.5104\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 950us/step - loss: 0.4754 - val_loss: 0.5063\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 904us/step - loss: 0.4726 - val_loss: 0.5025\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 881us/step - loss: 0.4699 - val_loss: 0.4999\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 945us/step - loss: 0.4679 - val_loss: 0.4970\n",
      "162/162 [==============================] - 0s 590us/step - loss: 0.4996\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=(5), name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=(6), name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "deep_input (InputLayer)         [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 30)           210         deep_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "wide_input (InputLayer)         [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 30)           930         dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 35)           0           wide_input[0][0]                 \n",
      "                                                                 dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 1)            36          concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "aux_output (Dense)              (None, 1)            31          dense_28[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,207\n",
      "Trainable params: 1,207\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.9703 - main_output_loss: 0.8940 - aux_output_loss: 1.6571 - val_loss: 0.6497 - val_main_output_loss: 0.5907 - val_aux_output_loss: 1.1809\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5675 - main_output_loss: 0.5203 - aux_output_loss: 0.9921 - val_loss: 0.5695 - val_main_output_loss: 0.5243 - val_aux_output_loss: 0.9770\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5223 - main_output_loss: 0.4863 - aux_output_loss: 0.8471 - val_loss: 0.7962 - val_main_output_loss: 0.7754 - val_aux_output_loss: 0.9838\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5106 - main_output_loss: 0.4814 - aux_output_loss: 0.7733 - val_loss: 0.5146 - val_main_output_loss: 0.4856 - val_aux_output_loss: 0.7755\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6431 - main_output_loss: 0.6268 - aux_output_loss: 0.7902 - val_loss: 0.5166 - val_main_output_loss: 0.4876 - val_aux_output_loss: 0.7774\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4905 - main_output_loss: 0.4675 - aux_output_loss: 0.6972 - val_loss: 0.6579 - val_main_output_loss: 0.6497 - val_aux_output_loss: 0.7325\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7105 - main_output_loss: 0.7161 - aux_output_loss: 0.6604 - val_loss: 0.4883 - val_main_output_loss: 0.4677 - val_aux_output_loss: 0.6733\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4634 - main_output_loss: 0.4454 - aux_output_loss: 0.6251 - val_loss: 0.4769 - val_main_output_loss: 0.4576 - val_aux_output_loss: 0.6509\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4627 - main_output_loss: 0.4458 - aux_output_loss: 0.6150 - val_loss: 0.4676 - val_main_output_loss: 0.4487 - val_aux_output_loss: 0.6369\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4388 - main_output_loss: 0.4219 - aux_output_loss: 0.5904 - val_loss: 0.4537 - val_main_output_loss: 0.4352 - val_aux_output_loss: 0.6200\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4280 - main_output_loss: 0.4100 - aux_output_loss: 0.5897 - val_loss: 0.4526 - val_main_output_loss: 0.4350 - val_aux_output_loss: 0.6116\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4186 - main_output_loss: 0.4011 - aux_output_loss: 0.5757 - val_loss: 0.4372 - val_main_output_loss: 0.4209 - val_aux_output_loss: 0.5839\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4170 - main_output_loss: 0.4010 - aux_output_loss: 0.5613 - val_loss: 0.4335 - val_main_output_loss: 0.4171 - val_aux_output_loss: 0.5803\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4075 - main_output_loss: 0.3914 - aux_output_loss: 0.5526 - val_loss: 0.4235 - val_main_output_loss: 0.4089 - val_aux_output_loss: 0.5556\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3963 - main_output_loss: 0.3809 - aux_output_loss: 0.5349 - val_loss: 0.4214 - val_main_output_loss: 0.4074 - val_aux_output_loss: 0.5474\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3883 - main_output_loss: 0.3735 - aux_output_loss: 0.5214 - val_loss: 0.4123 - val_main_output_loss: 0.3986 - val_aux_output_loss: 0.5361\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3862 - main_output_loss: 0.3724 - aux_output_loss: 0.5107 - val_loss: 0.4020 - val_main_output_loss: 0.3878 - val_aux_output_loss: 0.5300\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3783 - main_output_loss: 0.3640 - aux_output_loss: 0.5061 - val_loss: 0.3980 - val_main_output_loss: 0.3854 - val_aux_output_loss: 0.5120\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3745 - main_output_loss: 0.3610 - aux_output_loss: 0.4954 - val_loss: 0.3895 - val_main_output_loss: 0.3768 - val_aux_output_loss: 0.5042\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3660 - main_output_loss: 0.3525 - aux_output_loss: 0.4870 - val_loss: 0.3869 - val_main_output_loss: 0.3746 - val_aux_output_loss: 0.4978\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 784us/step - loss: 0.3952 - main_output_loss: 0.3836 - aux_output_loss: 0.4996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.39519599080085754, 0.3836006224155426, 0.4995548129081726)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate( [X_test_A, X_test_B], [y_test, y_test])\n",
    "total_loss, main_loss, aux_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.2887013],\n",
       "        [2.9159725],\n",
       "        [3.2446184]], dtype=float32),\n",
       " array([[1.5576848],\n",
       "        [2.826283 ],\n",
       "        [2.6450968]], dtype=float32))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])\n",
    "y_pred_main, y_pred_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs) # handles standard args (e.g., name)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "    \n",
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.9444 - output_1_loss: 0.7171 - output_2_loss: 1.2273 - val_loss: 1.3072 - val_output_1_loss: 0.5524 - val_output_2_loss: 0.7548\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2202 - output_1_loss: 0.4977 - output_2_loss: 0.7224 - val_loss: 1.1759 - val_output_1_loss: 0.4973 - val_output_2_loss: 0.6786\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0821 - output_1_loss: 0.4642 - output_2_loss: 0.6179 - val_loss: 1.0782 - val_output_1_loss: 0.4676 - val_output_2_loss: 0.6106\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9984 - output_1_loss: 0.4336 - output_2_loss: 0.5648 - val_loss: 1.0045 - val_output_1_loss: 0.4448 - val_output_2_loss: 0.5597\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9407 - output_1_loss: 0.4066 - output_2_loss: 0.5341 - val_loss: 0.9629 - val_output_1_loss: 0.4271 - val_output_2_loss: 0.5358\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8889 - output_1_loss: 0.4026 - output_2_loss: 0.4863 - val_loss: 0.8975 - val_output_1_loss: 0.4117 - val_output_2_loss: 0.4857\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8341 - output_1_loss: 0.3734 - output_2_loss: 0.4606 - val_loss: 0.8835 - val_output_1_loss: 0.4021 - val_output_2_loss: 0.4815\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8157 - output_1_loss: 0.3693 - output_2_loss: 0.4464 - val_loss: 0.9397 - val_output_1_loss: 0.4292 - val_output_2_loss: 0.5106\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8714 - output_1_loss: 0.4086 - output_2_loss: 0.4628 - val_loss: 0.8227 - val_output_1_loss: 0.3807 - val_output_2_loss: 0.4420\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8256 - output_1_loss: 0.4008 - output_2_loss: 0.4247 - val_loss: 0.7865 - val_output_1_loss: 0.3629 - val_output_2_loss: 0.4236\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7624 - output_1_loss: 0.3491 - output_2_loss: 0.4133 - val_loss: 0.8004 - val_output_1_loss: 0.3719 - val_output_2_loss: 0.4285\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7851 - output_1_loss: 0.3745 - output_2_loss: 0.4106 - val_loss: 0.8836 - val_output_1_loss: 0.3956 - val_output_2_loss: 0.4880\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7425 - output_1_loss: 0.3385 - output_2_loss: 0.4041 - val_loss: 0.8222 - val_output_1_loss: 0.3764 - val_output_2_loss: 0.4458\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7338 - output_1_loss: 0.3364 - output_2_loss: 0.3974 - val_loss: 0.7659 - val_output_1_loss: 0.3534 - val_output_2_loss: 0.4125\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7273 - output_1_loss: 0.3344 - output_2_loss: 0.3930 - val_loss: 0.7480 - val_output_1_loss: 0.3493 - val_output_2_loss: 0.3987\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7232 - output_1_loss: 0.3330 - output_2_loss: 0.3902 - val_loss: 0.7609 - val_output_1_loss: 0.3489 - val_output_2_loss: 0.4120\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7140 - output_1_loss: 0.3259 - output_2_loss: 0.3881 - val_loss: 0.7546 - val_output_1_loss: 0.3485 - val_output_2_loss: 0.4062\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7248 - output_1_loss: 0.3385 - output_2_loss: 0.3863 - val_loss: 0.7439 - val_output_1_loss: 0.3440 - val_output_2_loss: 0.4000\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7103 - output_1_loss: 0.3251 - output_2_loss: 0.3852 - val_loss: 0.7301 - val_output_1_loss: 0.3414 - val_output_2_loss: 0.3887\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7115 - output_1_loss: 0.3290 - output_2_loss: 0.3825 - val_loss: 0.7322 - val_output_1_loss: 0.3445 - val_output_2_loss: 0.3877\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='SGD')\n",
    "history =  model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                     validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-06456ea49a0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my_first_ann.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m   1976\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1977\u001b[0m     \"\"\"\n\u001b[0;32m-> 1978\u001b[0;31m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0m\u001b[1;32m   1979\u001b[0m                     signatures, options)\n\u001b[1;32m   1980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    121\u001b[0m     if (not model._is_graph_network and  # pylint:disable=protected-access\n\u001b[1;32m    122\u001b[0m         not isinstance(model, sequential.Sequential)):\n\u001b[0;32m--> 123\u001b[0;31m       raise NotImplementedError(\n\u001b[0m\u001b[1;32m    124\u001b[0m           \u001b[0;34m'Saving the model to HDF5 format requires the model to be a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m           \u001b[0;34m'Functional model or a Sequential model. It does not work for '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`."
     ]
    }
   ],
   "source": [
    "model.save('my_first_ann.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8542 - main_output_loss: 0.7340 - aux_output_loss: 1.9364 - val_loss: 0.6297 - val_main_output_loss: 0.5692 - val_aux_output_loss: 1.1745\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6558 - main_output_loss: 0.6139 - aux_output_loss: 1.0331 - val_loss: 0.5495 - val_main_output_loss: 0.5059 - val_aux_output_loss: 0.9420\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6191 - main_output_loss: 0.5893 - aux_output_loss: 0.8869 - val_loss: 1.4415 - val_main_output_loss: 1.4491 - val_aux_output_loss: 1.3732\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5570 - main_output_loss: 0.5204 - aux_output_loss: 0.8871 - val_loss: 0.5254 - val_main_output_loss: 0.4959 - val_aux_output_loss: 0.7914\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5233 - main_output_loss: 0.4982 - aux_output_loss: 0.7489 - val_loss: 0.5086 - val_main_output_loss: 0.4852 - val_aux_output_loss: 0.7191\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4694 - main_output_loss: 0.4452 - aux_output_loss: 0.6867 - val_loss: 0.4855 - val_main_output_loss: 0.4636 - val_aux_output_loss: 0.6834\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4568 - main_output_loss: 0.4343 - aux_output_loss: 0.6598 - val_loss: 0.4706 - val_main_output_loss: 0.4494 - val_aux_output_loss: 0.6620\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5277 - main_output_loss: 0.5151 - aux_output_loss: 0.6408 - val_loss: 0.4909 - val_main_output_loss: 0.4707 - val_aux_output_loss: 0.6733\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4372 - main_output_loss: 0.4167 - aux_output_loss: 0.6216 - val_loss: 0.4550 - val_main_output_loss: 0.4357 - val_aux_output_loss: 0.6288\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4222 - main_output_loss: 0.4024 - aux_output_loss: 0.6004 - val_loss: 0.4458 - val_main_output_loss: 0.4273 - val_aux_output_loss: 0.6116\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4134 - main_output_loss: 0.3948 - aux_output_loss: 0.5808 - val_loss: 0.4437 - val_main_output_loss: 0.4264 - val_aux_output_loss: 0.5993\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4038 - main_output_loss: 0.3850 - aux_output_loss: 0.5727 - val_loss: 0.4361 - val_main_output_loss: 0.4200 - val_aux_output_loss: 0.5804\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3977 - main_output_loss: 0.3806 - aux_output_loss: 0.5513 - val_loss: 0.4159 - val_main_output_loss: 0.3990 - val_aux_output_loss: 0.5687\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3881 - main_output_loss: 0.3704 - aux_output_loss: 0.5473 - val_loss: 0.4162 - val_main_output_loss: 0.4010 - val_aux_output_loss: 0.5529\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3806 - main_output_loss: 0.3641 - aux_output_loss: 0.5285 - val_loss: 0.4004 - val_main_output_loss: 0.3847 - val_aux_output_loss: 0.5420\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3731 - main_output_loss: 0.3572 - aux_output_loss: 0.5168 - val_loss: 0.3960 - val_main_output_loss: 0.3811 - val_aux_output_loss: 0.5306\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3689 - main_output_loss: 0.3535 - aux_output_loss: 0.5078 - val_loss: 0.4013 - val_main_output_loss: 0.3872 - val_aux_output_loss: 0.5285\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3621 - main_output_loss: 0.3470 - aux_output_loss: 0.4977 - val_loss: 0.3846 - val_main_output_loss: 0.3701 - val_aux_output_loss: 0.5144\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3596 - main_output_loss: 0.3453 - aux_output_loss: 0.4887 - val_loss: 0.3820 - val_main_output_loss: 0.3681 - val_aux_output_loss: 0.5070\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3554 - main_output_loss: 0.3412 - aux_output_loss: 0.4832 - val_loss: 0.3773 - val_main_output_loss: 0.3643 - val_aux_output_loss: 0.4945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x150d02d00>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_A = keras.layers.Input(shape=(5), name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=(6), name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])\n",
    "\n",
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")\n",
    "model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "          validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_first_ann.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('my_first_ann.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.2857 - main_output_loss: 1.1515 - aux_output_loss: 2.4932 - val_loss: 0.6919 - val_main_output_loss: 0.6100 - val_aux_output_loss: 1.4288\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6074 - main_output_loss: 0.5429 - aux_output_loss: 1.1873 - val_loss: 0.5838 - val_main_output_loss: 0.5236 - val_aux_output_loss: 1.1251\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5451 - main_output_loss: 0.4952 - aux_output_loss: 0.9945 - val_loss: 0.5449 - val_main_output_loss: 0.4982 - val_aux_output_loss: 0.9654\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5053 - main_output_loss: 0.4654 - aux_output_loss: 0.8651 - val_loss: 0.5221 - val_main_output_loss: 0.4844 - val_aux_output_loss: 0.8611\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4868 - main_output_loss: 0.4540 - aux_output_loss: 0.7824 - val_loss: 0.5179 - val_main_output_loss: 0.4890 - val_aux_output_loss: 0.7783\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4709 - main_output_loss: 0.4420 - aux_output_loss: 0.7316 - val_loss: 0.4858 - val_main_output_loss: 0.4578 - val_aux_output_loss: 0.7379\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4544 - main_output_loss: 0.4279 - aux_output_loss: 0.6933 - val_loss: 0.4744 - val_main_output_loss: 0.4482 - val_aux_output_loss: 0.7106\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4456 - main_output_loss: 0.4208 - aux_output_loss: 0.6684 - val_loss: 0.4664 - val_main_output_loss: 0.4423 - val_aux_output_loss: 0.6835\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4331 - main_output_loss: 0.4091 - aux_output_loss: 0.6488 - val_loss: 0.4542 - val_main_output_loss: 0.4313 - val_aux_output_loss: 0.6608\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4235 - main_output_loss: 0.4009 - aux_output_loss: 0.6266 - val_loss: 0.4436 - val_main_output_loss: 0.4214 - val_aux_output_loss: 0.6441\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4147 - main_output_loss: 0.3931 - aux_output_loss: 0.6084 - val_loss: 0.4359 - val_main_output_loss: 0.4146 - val_aux_output_loss: 0.6277\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4077 - main_output_loss: 0.3866 - aux_output_loss: 0.5975 - val_loss: 0.4336 - val_main_output_loss: 0.4138 - val_aux_output_loss: 0.6111\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4195 - main_output_loss: 0.3981 - aux_output_loss: 0.6122 - val_loss: 0.4334 - val_main_output_loss: 0.4110 - val_aux_output_loss: 0.6350\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4137 - main_output_loss: 0.3959 - aux_output_loss: 0.5736 - val_loss: 0.4195 - val_main_output_loss: 0.4013 - val_aux_output_loss: 0.5832\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4295 - main_output_loss: 0.4166 - aux_output_loss: 0.5459 - val_loss: 0.4369 - val_main_output_loss: 0.4220 - val_aux_output_loss: 0.5704\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3892 - main_output_loss: 0.3725 - aux_output_loss: 0.5394 - val_loss: 0.4029 - val_main_output_loss: 0.3862 - val_aux_output_loss: 0.5528\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3740 - main_output_loss: 0.3571 - aux_output_loss: 0.5258 - val_loss: 0.3937 - val_main_output_loss: 0.3771 - val_aux_output_loss: 0.5427\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3680 - main_output_loss: 0.3515 - aux_output_loss: 0.5161 - val_loss: 0.3935 - val_main_output_loss: 0.3780 - val_aux_output_loss: 0.5332\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3639 - main_output_loss: 0.3482 - aux_output_loss: 0.5045 - val_loss: 0.3876 - val_main_output_loss: 0.3718 - val_aux_output_loss: 0.5293\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3582 - main_output_loss: 0.3428 - aux_output_loss: 0.4968 - val_loss: 0.3850 - val_main_output_loss: 0.3706 - val_aux_output_loss: 0.5149\n"
     ]
    }
   ],
   "source": [
    "input_A = keras.layers.Input(shape=(5), name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=(6), name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])\n",
    "\n",
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]), callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 712us/step - loss: 0.3877 - main_output_loss: 0.3739 - aux_output_loss: 0.5115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3876643776893616, 0.3739095628261566, 0.5114568471908569]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir(): \n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_logs/run_2020_12_01-14_44_52'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  1/363 [..............................] - ETA: 0s - loss: 0.2753 - main_output_loss: 0.2540 - aux_output_loss: 0.4669WARNING:tensorflow:From /Users/Dipper/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0035s vs `on_train_batch_end` time: 0.0388s). Check your callbacks.\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3571 - main_output_loss: 0.3425 - aux_output_loss: 0.4892 - val_loss: 0.3845 - val_main_output_loss: 0.3708 - val_aux_output_loss: 0.5085\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3537 - main_output_loss: 0.3395 - aux_output_loss: 0.4808 - val_loss: 0.3806 - val_main_output_loss: 0.3667 - val_aux_output_loss: 0.5055\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3516 - main_output_loss: 0.3379 - aux_output_loss: 0.4752 - val_loss: 0.3715 - val_main_output_loss: 0.3577 - val_aux_output_loss: 0.4955\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3467 - main_output_loss: 0.3330 - aux_output_loss: 0.4700 - val_loss: 0.3674 - val_main_output_loss: 0.3544 - val_aux_output_loss: 0.4850\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3448 - main_output_loss: 0.3313 - aux_output_loss: 0.4660 - val_loss: 0.3790 - val_main_output_loss: 0.3656 - val_aux_output_loss: 0.4994\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3435 - main_output_loss: 0.3303 - aux_output_loss: 0.4616 - val_loss: 0.3647 - val_main_output_loss: 0.3524 - val_aux_output_loss: 0.4758\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3398 - main_output_loss: 0.3269 - aux_output_loss: 0.4558 - val_loss: 0.3621 - val_main_output_loss: 0.3500 - val_aux_output_loss: 0.4711\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3398 - main_output_loss: 0.3271 - aux_output_loss: 0.4539 - val_loss: 0.3653 - val_main_output_loss: 0.3536 - val_aux_output_loss: 0.4699\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3372 - main_output_loss: 0.3250 - aux_output_loss: 0.4478 - val_loss: 0.3582 - val_main_output_loss: 0.3464 - val_aux_output_loss: 0.4639\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3348 - main_output_loss: 0.3227 - aux_output_loss: 0.4440 - val_loss: 0.3702 - val_main_output_loss: 0.3590 - val_aux_output_loss: 0.4703\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3359 - main_output_loss: 0.3242 - aux_output_loss: 0.4407 - val_loss: 0.3551 - val_main_output_loss: 0.3441 - val_aux_output_loss: 0.4547\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3367 - main_output_loss: 0.3253 - aux_output_loss: 0.4390 - val_loss: 0.3536 - val_main_output_loss: 0.3424 - val_aux_output_loss: 0.4545\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3310 - main_output_loss: 0.3194 - aux_output_loss: 0.4357 - val_loss: 0.3518 - val_main_output_loss: 0.3411 - val_aux_output_loss: 0.4485\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3303 - main_output_loss: 0.3188 - aux_output_loss: 0.4334 - val_loss: 0.3544 - val_main_output_loss: 0.3438 - val_aux_output_loss: 0.4498\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3314 - main_output_loss: 0.3203 - aux_output_loss: 0.4317 - val_loss: 0.3524 - val_main_output_loss: 0.3419 - val_aux_output_loss: 0.4473\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3278 - main_output_loss: 0.3167 - aux_output_loss: 0.4272 - val_loss: 0.3557 - val_main_output_loss: 0.3462 - val_aux_output_loss: 0.4415\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3283 - main_output_loss: 0.3176 - aux_output_loss: 0.4242 - val_loss: 0.3611 - val_main_output_loss: 0.3509 - val_aux_output_loss: 0.4535\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3269 - main_output_loss: 0.3160 - aux_output_loss: 0.4247 - val_loss: 0.3562 - val_main_output_loss: 0.3464 - val_aux_output_loss: 0.4444\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3279 - main_output_loss: 0.3173 - aux_output_loss: 0.4226 - val_loss: 0.3547 - val_main_output_loss: 0.3455 - val_aux_output_loss: 0.4372\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3249 - main_output_loss: 0.3143 - aux_output_loss: 0.4203 - val_loss: 0.3497 - val_main_output_loss: 0.3398 - val_aux_output_loss: 0.4381\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]),\n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000 + 1):\n",
    "        tf.summary.scalar(\"my_scalar\", np.sin(step / 10), step=step)\n",
    "        data = (np.random.randn(100) + 2) * step / 100 # some random data\n",
    "        tf.summary.histogram(\"my_hist\", data, buckets=50, step=step)\n",
    "        images = np.random.rand(2, 32, 32, 3) # random 32×32 RGB images\n",
    "        tf.summary.image(\"my_images\", images * step / 1000, step=step)\n",
    "        texts = [\"The step is \" + str(step), \"Its square is \" + str(step**2)]\n",
    "        tf.summary.text(\"my_text\", texts, step=step)\n",
    "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio(\"my_audio\", audio, sample_rate=48000, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2482 - val_loss: 0.7781\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 771us/step - loss: 0.6628 - val_loss: 0.6699\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 828us/step - loss: 0.5755 - val_loss: 0.6075\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 847us/step - loss: 0.5315 - val_loss: 0.5719\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 847us/step - loss: 0.5053 - val_loss: 0.5433\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 836us/step - loss: 0.4882 - val_loss: 0.5250\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 828us/step - loss: 0.4793 - val_loss: 0.5118\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 832us/step - loss: 0.4694 - val_loss: 0.5013\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 856us/step - loss: 0.4654 - val_loss: 0.4956\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 833us/step - loss: 0.4583 - val_loss: 0.4926\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 826us/step - loss: 0.4544 - val_loss: 0.4882\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 817us/step - loss: 0.4511 - val_loss: 0.4893\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 830us/step - loss: 0.4481 - val_loss: 0.4798\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 806us/step - loss: 0.4429 - val_loss: 0.4780\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 865us/step - loss: 0.4402 - val_loss: 0.4715\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4371 - val_loss: 0.4706\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 815us/step - loss: 0.4346 - val_loss: 0.4708\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 809us/step - loss: 0.4333 - val_loss: 0.4721\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 820us/step - loss: 0.4304 - val_loss: 0.4651\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 901us/step - loss: 0.4281 - val_loss: 0.4615\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 842us/step - loss: 0.4263 - val_loss: 0.4608\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 853us/step - loss: 0.4242 - val_loss: 0.4587\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 922us/step - loss: 0.4227 - val_loss: 0.4554\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4202 - val_loss: 0.4529\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4181 - val_loss: 0.4549\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 842us/step - loss: 0.4166 - val_loss: 0.4495\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 845us/step - loss: 0.4152 - val_loss: 0.4491\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 822us/step - loss: 0.4137 - val_loss: 0.4458\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 918us/step - loss: 0.4119 - val_loss: 0.4466\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4104 - val_loss: 0.4450\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4075 - val_loss: 0.4439\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 882us/step - loss: 0.4073 - val_loss: 0.4420\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 855us/step - loss: 0.4052 - val_loss: 0.4406\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 820us/step - loss: 0.4044 - val_loss: 0.4382\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.4017 - val_loss: 0.4361\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3997 - val_loss: 0.4411\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3991 - val_loss: 0.4333\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 872us/step - loss: 0.3979 - val_loss: 0.4335\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 852us/step - loss: 0.3960 - val_loss: 0.4321\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 805us/step - loss: 0.3943 - val_loss: 0.4299\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.3939 - val_loss: 0.4274\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 829us/step - loss: 0.3920 - val_loss: 0.4269\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 795us/step - loss: 0.3910 - val_loss: 0.4260\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.3901 - val_loss: 0.4304\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3880 - val_loss: 0.4241\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 830us/step - loss: 0.3861 - val_loss: 0.4260\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 834us/step - loss: 0.3854 - val_loss: 0.4218\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 830us/step - loss: 0.3850 - val_loss: 0.4251\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 828us/step - loss: 0.3845 - val_loss: 0.4200\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 816us/step - loss: 0.3837 - val_loss: 0.4214\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 837us/step - loss: 0.3826 - val_loss: 0.4175\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.3793 - val_loss: 0.4176\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 849us/step - loss: 0.3773 - val_loss: 0.4180\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 804us/step - loss: 0.3775 - val_loss: 0.4116\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 797us/step - loss: 0.3756 - val_loss: 0.4132\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 818us/step - loss: 0.3768 - val_loss: 0.4100\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3746 - val_loss: 0.4129\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 806us/step - loss: 0.3733 - val_loss: 0.4125\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 804us/step - loss: 0.3720 - val_loss: 0.4089\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 829us/step - loss: 0.3718 - val_loss: 0.4091\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 871us/step - loss: 0.3692 - val_loss: 0.4077\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3688 - val_loss: 0.4080\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3684 - val_loss: 0.4071\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 840us/step - loss: 0.3711 - val_loss: 0.4093\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3686 - val_loss: 0.4028\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3666 - val_loss: 0.4024\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 834us/step - loss: 0.3643 - val_loss: 0.4055\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 782us/step - loss: 0.3656 - val_loss: 0.4053\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 959us/step - loss: 0.3647 - val_loss: 0.4043\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 900us/step - loss: 0.3632 - val_loss: 0.3993\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3596 - val_loss: 0.4033\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3610 - val_loss: 0.3981\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.3990\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3573 - val_loss: 0.3969\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3618 - val_loss: 0.3968\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3616 - val_loss: 0.3965\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.3950\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3540 - val_loss: 0.3993\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 949us/step - loss: 0.3542 - val_loss: 0.3959\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3521 - val_loss: 0.3922\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.3922\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3555 - val_loss: 0.3918\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3627 - val_loss: 0.3910\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3496 - val_loss: 0.3944\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 740us/step - loss: 0.3505 - val_loss: 0.3947\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 822us/step - loss: 0.3715 - val_loss: 0.3868\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 785us/step - loss: 0.3510 - val_loss: 0.3887\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 828us/step - loss: 0.3520 - val_loss: 0.3864\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 824us/step - loss: 0.3530 - val_loss: 0.4301\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 796us/step - loss: 0.3589 - val_loss: 0.3881\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 833us/step - loss: 0.3507 - val_loss: 0.3866\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 842us/step - loss: 0.3454 - val_loss: 0.3804\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 834us/step - loss: 0.3460 - val_loss: 0.3819\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 838us/step - loss: 0.3435 - val_loss: 0.3865\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 805us/step - loss: 0.3441 - val_loss: 0.4050\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 778us/step - loss: 0.3444 - val_loss: 0.3799\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 788us/step - loss: 0.3746 - val_loss: 0.3791\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 804us/step - loss: 0.3449 - val_loss: 0.3802\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 790us/step - loss: 0.3449 - val_loss: 0.5330\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 775us/step - loss: 0.5209 - val_loss: 0.3805\n",
      "162/162 [==============================] - 0s 556us/step - loss: 0.3773\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1664 - val_loss: 0.7412\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.6242 - val_loss: 0.6439\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.5590 - val_loss: 0.5800\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.5132 - val_loss: 0.5406\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.4897 - val_loss: 0.5205\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.4745 - val_loss: 0.5064\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.4652 - val_loss: 0.4948\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.4599 - val_loss: 0.4886\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.4533 - val_loss: 0.4867\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.4522 - val_loss: 0.4785\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.4452 - val_loss: 0.4754\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.4414 - val_loss: 0.4696\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 924us/step - loss: 0.4380 - val_loss: 0.4663\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.4345 - val_loss: 0.4625\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.4322 - val_loss: 0.4625\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.4298 - val_loss: 0.4580\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.4271 - val_loss: 0.4583\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4258 - val_loss: 0.4528\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.4186 - val_loss: 0.4528\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.4167 - val_loss: 0.4453\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.4154 - val_loss: 0.4426\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.4127 - val_loss: 0.4404\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.4089 - val_loss: 0.4370\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4056 - val_loss: 0.4426\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4041 - val_loss: 0.4326\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.4090 - val_loss: 0.4326\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4019 - val_loss: 0.4355\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3973 - val_loss: 0.4294\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.4010 - val_loss: 0.4263\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.3938 - val_loss: 0.4281\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.3978 - val_loss: 0.4231\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.3900 - val_loss: 0.4238\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.3902 - val_loss: 0.4172\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.3880 - val_loss: 0.4189\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.3852 - val_loss: 0.4193\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.3834 - val_loss: 0.4146\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.3850 - val_loss: 0.4126\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.3828 - val_loss: 0.4123\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.3794 - val_loss: 0.4087\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.3843 - val_loss: 0.4117\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3788 - val_loss: 0.4072\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.3810 - val_loss: 0.4029\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.3795 - val_loss: 0.4123\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 0.3881 - val_loss: 0.4087\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.3753 - val_loss: 0.4051\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.3729 - val_loss: 0.4024\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.3711 - val_loss: 0.3970\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.3699 - val_loss: 0.3997\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.3670 - val_loss: 0.3967\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.3685 - val_loss: 0.3967\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.3658 - val_loss: 0.3969\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.3661 - val_loss: 0.3991\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3645 - val_loss: 0.3971\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.3680 - val_loss: 0.3952\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.3647 - val_loss: 0.3953\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.3660 - val_loss: 0.3901\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.3593 - val_loss: 0.3960\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.3596 - val_loss: 0.3878\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.3586 - val_loss: 0.3878\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.3581 - val_loss: 0.3862\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.3628 - val_loss: 0.3890\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.3550 - val_loss: 0.3872\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 924us/step - loss: 0.3551 - val_loss: 0.3861\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.3579 - val_loss: 0.4901\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.3820 - val_loss: 0.3872\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.3624 - val_loss: 0.4012\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.3548 - val_loss: 0.3840\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.3877 - val_loss: 0.3853\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3546 - val_loss: 0.4540\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.4230 - val_loss: 0.3803\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.3512 - val_loss: 0.4708\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.3572 - val_loss: 0.3817\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.3491 - val_loss: 0.3809\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.3531 - val_loss: 0.3814\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3489 - val_loss: 0.3780\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.3469 - val_loss: 0.3767\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.3505 - val_loss: 0.4875\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.3709 - val_loss: 0.3778\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 0.3449 - val_loss: 0.3785\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 908us/step - loss: 0.3453 - val_loss: 0.3760\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.3425 - val_loss: 0.3794\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.3448 - val_loss: 0.4063\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.3419 - val_loss: 0.3720\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3396 - val_loss: 0.3716\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.3392 - val_loss: 0.3715\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.4005 - val_loss: 0.3755\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3462 - val_loss: 0.3700\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.3393 - val_loss: 0.3730\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.3393 - val_loss: 0.3692\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.3387 - val_loss: 0.3718\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.3407 - val_loss: 0.3671\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.3353 - val_loss: 0.3674\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 887us/step - loss: 0.3462 - val_loss: 0.3856\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.3367 - val_loss: 0.3830\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 883us/step - loss: 0.3450 - val_loss: 0.3693\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.3330 - val_loss: 0.3666\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.3350 - val_loss: 0.3642\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.3411 - val_loss: 0.3676\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.3320 - val_loss: 0.3651\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.3359 - val_loss: 0.3655\n",
      "121/121 [==============================] - 0s 564us/step - loss: 0.3316\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2047 - val_loss: 0.7418\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.8912 - val_loss: 0.6524\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.6312 - val_loss: 0.6029\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.5843 - val_loss: 0.5770\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.5272 - val_loss: 0.5488\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.5095 - val_loss: 0.5303\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.4925 - val_loss: 0.5165\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.4956 - val_loss: 0.5070\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.4800 - val_loss: 0.4986\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 887us/step - loss: 0.4698 - val_loss: 0.4923\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.4685 - val_loss: 0.4892\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.4626 - val_loss: 0.4820\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.4691 - val_loss: 0.4809\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.4514 - val_loss: 0.4753\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.4517 - val_loss: 0.4741\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.4453 - val_loss: 0.5104\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.4465 - val_loss: 0.4708\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.4422 - val_loss: 0.4678\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.4347 - val_loss: 0.4644\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.4341 - val_loss: 0.4601\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.4316 - val_loss: 0.4589\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 924us/step - loss: 0.4290 - val_loss: 0.4617\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.4273 - val_loss: 0.4518\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.4247 - val_loss: 0.4504\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.4257 - val_loss: 0.4533\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.4204 - val_loss: 0.4440\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.4180 - val_loss: 0.4496\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.4151 - val_loss: 0.4400\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.4200 - val_loss: 0.4390\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.4134 - val_loss: 0.4377\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.4102 - val_loss: 0.4328\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.4094 - val_loss: 0.4344\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.4051 - val_loss: 0.4359\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.4033 - val_loss: 0.4281\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.4114 - val_loss: 0.4337\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.3998 - val_loss: 0.4261\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.3983 - val_loss: 0.4278\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.3973 - val_loss: 0.4236\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.3967 - val_loss: 0.4208\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.3928 - val_loss: 0.4220\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3956 - val_loss: 0.4238\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.3957 - val_loss: 0.4184\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.3912 - val_loss: 0.4206\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3872 - val_loss: 0.4178\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.3899 - val_loss: 0.4146\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.3848 - val_loss: 0.4331\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.4165 - val_loss: 0.4094\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.3819 - val_loss: 0.4128\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.3853 - val_loss: 0.4079\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.3939 - val_loss: 0.4047\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.3924 - val_loss: 0.4090\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.3782 - val_loss: 0.4072\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.3837 - val_loss: 0.4062\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3795 - val_loss: 0.4028\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.3736 - val_loss: 0.3990\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.3859 - val_loss: 0.4030\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.3719 - val_loss: 0.4285\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.3746 - val_loss: 0.3984\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.3784 - val_loss: 0.4009\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.3942 - val_loss: 0.3967\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.3670 - val_loss: 0.4059\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.3806 - val_loss: 0.3962\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.3644 - val_loss: 0.3957\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.3653 - val_loss: 0.3949\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.3627 - val_loss: 0.3938\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1000us/step - loss: 0.3610 - val_loss: 0.3994\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3627 - val_loss: 0.3919\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3662 - val_loss: 0.4075\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3616 - val_loss: 0.3926\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3600 - val_loss: 0.4605\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3653 - val_loss: 0.3988\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3585 - val_loss: 0.3889\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3562 - val_loss: 0.3921\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3747 - val_loss: 0.3931\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3568 - val_loss: 0.3894\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3603 - val_loss: 0.3876\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3537 - val_loss: 0.3893\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3542 - val_loss: 0.3896\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.4529\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.3580 - val_loss: 0.3878\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 887us/step - loss: 0.3616 - val_loss: 0.3814\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3589 - val_loss: 0.3876\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.3630 - val_loss: 0.3844\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.3524 - val_loss: 0.3846\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.3527 - val_loss: 0.3806\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.3759 - val_loss: 0.3777\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.3509 - val_loss: 0.4731\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.3692 - val_loss: 0.3761\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3476 - val_loss: 0.3783\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.3613 - val_loss: 0.3805\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.3664 - val_loss: 0.3777\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.3476 - val_loss: 0.3784\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.3585 - val_loss: 0.3807\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.3448 - val_loss: 0.3823\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.3476 - val_loss: 0.3778\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.3518 - val_loss: 0.3750\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.3481 - val_loss: 0.3748\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.3514 - val_loss: 0.3816\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.3545 - val_loss: 0.3845\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.3456 - val_loss: 0.3759\n",
      "121/121 [==============================] - 0s 524us/step - loss: 0.3483\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2308 - val_loss: 0.8344\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.6836 - val_loss: 0.7042\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5765 - val_loss: 0.6319\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5298 - val_loss: 0.5864\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.4983 - val_loss: 0.5571\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.4838 - val_loss: 0.5493\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.4654 - val_loss: 0.5168\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.4567 - val_loss: 0.5158\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 0.4446 - val_loss: 0.4954\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 0.4359 - val_loss: 0.4902\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.4289 - val_loss: 0.4822\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.4237 - val_loss: 0.4755\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.4196 - val_loss: 0.4726\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.4149 - val_loss: 0.4733\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.4178 - val_loss: 0.4622\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.4224 - val_loss: 0.5028\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.4510 - val_loss: 0.4668\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.4623 - val_loss: 0.4636\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.4083 - val_loss: 0.4585\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.4036 - val_loss: 0.4514\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.4185 - val_loss: 0.4528\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.4006 - val_loss: 0.4485\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.4238 - val_loss: 0.4468\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.3959 - val_loss: 0.4447\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.3922 - val_loss: 0.4405\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.3901 - val_loss: 0.4395\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.3877 - val_loss: 0.4440\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.3861 - val_loss: 0.4360\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.3875 - val_loss: 0.4387\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.3846 - val_loss: 0.4336\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.3945 - val_loss: 0.4384\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.3813 - val_loss: 0.4310\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.3792 - val_loss: 0.4326\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.3914 - val_loss: 0.4305\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3790 - val_loss: 0.4266\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 870us/step - loss: 0.3748 - val_loss: 0.4281\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3754 - val_loss: 0.4243\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3809 - val_loss: 0.5683\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.3930 - val_loss: 0.4216\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3715 - val_loss: 0.4204\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.3736 - val_loss: 0.4204\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.3677 - val_loss: 0.4285\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3699 - val_loss: 0.4436\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.3664 - val_loss: 0.4136\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3776 - val_loss: 0.4163\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.3823 - val_loss: 0.4209\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.3652 - val_loss: 0.4193\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.3760 - val_loss: 0.4119\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.3671 - val_loss: 0.4088\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.4118 - val_loss: 0.4132\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.4055 - val_loss: 0.4170\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.3671 - val_loss: 0.4142\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.3666 - val_loss: 0.4174\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.3641 - val_loss: 0.4103\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.3598 - val_loss: 0.4033\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.3580 - val_loss: 0.4118\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.3868 - val_loss: 0.4063\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.3615 - val_loss: 0.4055\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.3574 - val_loss: 0.4008\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3540 - val_loss: 0.3958\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.4003\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.3530 - val_loss: 0.3991\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 887us/step - loss: 0.3533 - val_loss: 0.3970\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.3502 - val_loss: 0.3952\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.3468 - val_loss: 0.3910\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3461 - val_loss: 0.3922\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.3889\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3440 - val_loss: 0.3908\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.3462 - val_loss: 0.3898\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.3467 - val_loss: 0.3950\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.3476 - val_loss: 0.3883\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.3411 - val_loss: 0.3846\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.3391 - val_loss: 0.3820\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3389 - val_loss: 0.3824\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.3391 - val_loss: 0.3831\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.3386 - val_loss: 0.3863\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.3360 - val_loss: 0.3879\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.3370 - val_loss: 0.3856\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.3353 - val_loss: 0.3757\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.3342 - val_loss: 0.3754\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.3379 - val_loss: 0.4002\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.3353 - val_loss: 0.3794\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.3321 - val_loss: 0.3845\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.3309 - val_loss: 0.3757\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.3364 - val_loss: 0.3733\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.3303 - val_loss: 0.3721\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.3314 - val_loss: 0.3740\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.4584 - val_loss: 0.3805\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.3305 - val_loss: 0.3716\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3286 - val_loss: 0.3717\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.3279 - val_loss: 0.3736\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.3362 - val_loss: 0.3747\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.3278 - val_loss: 0.3695\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.3281 - val_loss: 0.3697\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.3250 - val_loss: 0.3718\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.3368 - val_loss: 0.3706\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.3442 - val_loss: 0.3641\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.3649 - val_loss: 0.3908\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.3492 - val_loss: 0.3740\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.3322 - val_loss: 0.3776\n",
      "121/121 [==============================] - 0s 564us/step - loss: 0.3720\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9431 - val_loss: 0.4978\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4727 - val_loss: 0.4708\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4447 - val_loss: 0.5339\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4305 - val_loss: 0.4393\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4094 - val_loss: 0.4749\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3988 - val_loss: 0.4295\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.3911 - val_loss: 0.4082\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3851 - val_loss: 0.4860\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.3928\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5018 - val_loss: 0.5799\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 620us/step - loss: nan\n",
      "Epoch 1/100\n",
      "201/242 [=======================>......] - ETA: 0s - loss: 0.9037"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-2a66724c63a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   \"learning_rate\": reciprocal(3e-4, 3e-2)}\n\u001b[1;32m      6\u001b[0m \u001b[0mrnd_search_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distribs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m rnd_search_cv.fit(X_train, y_train, epochs=100,\n\u001b[0m\u001b[1;32m      8\u001b[0m                   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                   callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1527\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m         evaluate_candidates(ParameterSampler(\n\u001b[0m\u001b[1;32m   1530\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m             random_state=self.random_state))\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1121\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1123\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1124\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 696\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    697\u001b[0m             *args, **kwds))\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3065\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    960\u001b[0m           \u001b[0;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m             return autograph.converted_call(\n\u001b[0m\u001b[1;32m    963\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_whitelisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1217\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1209\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1210\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1211\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m   \u001b[0;31m# TODO(b/151224785): Remove deprecated alias.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2583\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2585\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2587\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2943\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2944\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2945\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2947\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperimental_hints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_whitelisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1209\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `test_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m     \u001b[0;31m# Updates stateful loss metrics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m     self.compiled_loss(\n\u001b[0m\u001b[1;32m   1177\u001b[0m         y, y_pred, sample_weight, regularization_losses=self.losses)\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight, regularization_losses)\u001b[0m\n\u001b[1;32m    202\u001b[0m       \u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch_dtype_and_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0msw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m       \u001b[0mloss_metric_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m       \u001b[0mag_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m       \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m       return losses_utils.compute_weighted_loss(\n\u001b[1;32m    151\u001b[0m           losses, sample_weight, reduction=self._get_reduction())\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_whitelist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Whitelisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    251\u001b[0m           y_pred, y_true)\n\u001b[1;32m    252\u001b[0m     \u001b[0mag_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mag_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m   1193\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m   \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquared_difference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36msquared_difference\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m  10396\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10397\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10398\u001b[0;31m     _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m  10399\u001b[0m         \"SquaredDifference\", x=x, y=y, name=name)\n\u001b[1;32m  10400\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    740\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    743\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    592\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         compute_device)\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3475\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3476\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3477\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3478\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3479\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1985\u001b[0m       \u001b[0mtf_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1986\u001b[0m       \u001b[0moutput_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationOutputType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1987\u001b[0;31m       \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_with_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1988\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_with_tf_output\u001b[0;34m(op, value_index, dtype, tf_output)\u001b[0m\n\u001b[1;32m    386\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_with_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, op, value_index, dtype)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m     \u001b[0;31m# This will be set by self._as_tf_output().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/machine_learning/ml_env/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36mas_dtype\u001b[0;34m(type_value)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtype_value\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDType\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m   \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_INTERN_TABLE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_distribs = {\"n_hidden\": [0, 1, 2, 3],\n",
    "                  \"n_neurons\": np.arange(1, 100),\n",
    "                  \"learning_rate\": reciprocal(3e-4, 3e-2)}\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.Dense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.constant([[1, 2, 3], [4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1.,2.], [4.,5.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[ 9, 12, 15],\n",
       "       [24, 33, 42]], dtype=int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a@b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]], dtype=int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold=1.0): \n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
       "array([[1.5, 1.5],\n",
       "       [1.5, 1.5]])>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.array([[3.,4.], [6.,7.]])\n",
    "create_huber()(a, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(w1, w2):\n",
    "    return 3*w1**2+2*w1*w2\n",
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "gradients = tape.gradient(z, [w1, w2])\n",
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x): \n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x143063be0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'sdhsjka'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant('sdhsjka')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "a[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.] * 8 + [tf.constant([], dtype=tf.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\", input_shape=[28, 28, 1]),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_sample_image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 427, 640, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "china = load_sample_image(\"china.jpg\") / 255\n",
    "flower = load_sample_image(\"flower.jpg\") / 255\n",
    "images = np.array([china, flower])\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = keras.layers.Conv2D(filters=32, kernel_size=3, strides=2,\n",
    "                           padding=\"SAME\", activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer conv2d_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x154a89220>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def crop(images):\n",
    "    return images[150:220, 130:250]\n",
    "outputs = conv(images)\n",
    "plt.imshow(crop(outputs[0, :, :, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualUnit(keras.layers.Layer):\n",
    "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.main_layers = [\n",
    "            keras.layers.Conv2D(filters, 3, strides=strides, padding=\"same\", use_bias=False),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            keras.layers.Conv2D(filters, 3, strides=1, padding=\"same\", use_bias=False),\n",
    "            keras.layers.BatchNormalization()]\n",
    "        self.skip_layers = []\n",
    "        if strides > 1:\n",
    "            self.skip_layers = [\n",
    "                keras.layers.Conv2D(filters, 1, strides=strides,padding=\"same\", use_bias=False),\n",
    "                keras.layers.BatchNormalization()]\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.main_layers:\n",
    "            Z = layer(Z)\n",
    "        skip_Z = inputs\n",
    "        for layer in self.skip_layers:\n",
    "            skip_Z = layer(skip_Z)\n",
    "        return self.activation(Z + skip_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(64, 7, strides=2, input_shape=[224, 224, 3],padding=\"same\", use_bias=False))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation(\"relu\"))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"same\"))\n",
    "prev_filters = 64\n",
    "for filters in [64]*3 + [128]*4 + [256]*6 + [512]*3:\n",
    "    strides = 1 if filters == prev_filters else 2\n",
    "    model.add(ResidualUnit(filters, strides=strides))\n",
    "    prev_filters = filters\n",
    "model.add(keras.layers.GlobalAvgPool2D())\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 112, 112, 64)      9408      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "residual_unit (ResidualUnit) (None, 56, 56, 64)        74240     \n",
      "_________________________________________________________________\n",
      "residual_unit_1 (ResidualUni (None, 56, 56, 64)        74240     \n",
      "_________________________________________________________________\n",
      "residual_unit_2 (ResidualUni (None, 56, 56, 64)        74240     \n",
      "_________________________________________________________________\n",
      "residual_unit_3 (ResidualUni (None, 28, 28, 128)       230912    \n",
      "_________________________________________________________________\n",
      "residual_unit_4 (ResidualUni (None, 28, 28, 128)       295936    \n",
      "_________________________________________________________________\n",
      "residual_unit_5 (ResidualUni (None, 28, 28, 128)       295936    \n",
      "_________________________________________________________________\n",
      "residual_unit_6 (ResidualUni (None, 28, 28, 128)       295936    \n",
      "_________________________________________________________________\n",
      "residual_unit_7 (ResidualUni (None, 14, 14, 256)       920576    \n",
      "_________________________________________________________________\n",
      "residual_unit_8 (ResidualUni (None, 14, 14, 256)       1181696   \n",
      "_________________________________________________________________\n",
      "residual_unit_9 (ResidualUni (None, 14, 14, 256)       1181696   \n",
      "_________________________________________________________________\n",
      "residual_unit_10 (ResidualUn (None, 14, 14, 256)       1181696   \n",
      "_________________________________________________________________\n",
      "residual_unit_11 (ResidualUn (None, 14, 14, 256)       1181696   \n",
      "_________________________________________________________________\n",
      "residual_unit_12 (ResidualUn (None, 14, 14, 256)       1181696   \n",
      "_________________________________________________________________\n",
      "residual_unit_13 (ResidualUn (None, 7, 7, 512)         3676160   \n",
      "_________________________________________________________________\n",
      "residual_unit_14 (ResidualUn (None, 7, 7, 512)         4722688   \n",
      "_________________________________________________________________\n",
      "residual_unit_15 (ResidualUn (None, 7, 7, 512)         4722688   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 21,306,826\n",
      "Trainable params: 21,289,802\n",
      "Non-trainable params: 17,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(batch_size, n_steps):\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10)) # wave 1\n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20)) # + wave 2\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5) # + noise\n",
    "    return series[..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.00643636e-01, -8.80235473e-01, -8.59827309e-01,\n",
       "        -8.39419146e-01, -8.19010983e-01, -7.98602820e-01,\n",
       "        -7.78194656e-01, -7.57786493e-01, -7.37378330e-01,\n",
       "        -7.16970167e-01, -6.96562003e-01, -6.76153840e-01,\n",
       "        -6.55745677e-01, -6.35337514e-01, -6.14929350e-01,\n",
       "        -5.94521187e-01, -5.74113024e-01, -5.53704860e-01,\n",
       "        -5.33296697e-01, -5.12888534e-01, -4.92480371e-01,\n",
       "        -4.72072207e-01, -4.51664044e-01, -4.31255881e-01,\n",
       "        -4.10847718e-01, -3.90439554e-01, -3.70031391e-01,\n",
       "        -3.49623228e-01, -3.29215065e-01, -3.08806901e-01,\n",
       "        -2.88398738e-01, -2.67990575e-01, -2.47582412e-01,\n",
       "        -2.27174248e-01, -2.06766085e-01, -1.86357922e-01,\n",
       "        -1.65949758e-01, -1.45541595e-01, -1.25133432e-01,\n",
       "        -1.04725269e-01, -8.43171054e-02, -6.39089421e-02,\n",
       "        -4.35007789e-02, -2.30926156e-02, -2.68445233e-03,\n",
       "         1.77237109e-02,  3.81318742e-02,  5.85400375e-02,\n",
       "         7.89482007e-02,  9.93563640e-02],\n",
       "       [-2.85076418e-01, -2.64668254e-01, -2.44260091e-01,\n",
       "        -2.23851928e-01, -2.03443765e-01, -1.83035601e-01,\n",
       "        -1.62627438e-01, -1.42219275e-01, -1.21811111e-01,\n",
       "        -1.01402948e-01, -8.09947849e-02, -6.05866217e-02,\n",
       "        -4.01784584e-02, -1.97702952e-02,  6.37868113e-04,\n",
       "         2.10460314e-02,  4.14541946e-02,  6.18623579e-02,\n",
       "         8.22705212e-02,  1.02678684e-01,  1.23086848e-01,\n",
       "         1.43495011e-01,  1.63903174e-01,  1.84311338e-01,\n",
       "         2.04719501e-01,  2.25127664e-01,  2.45535827e-01,\n",
       "         2.65943991e-01,  2.86352154e-01,  3.06760317e-01,\n",
       "         3.27168480e-01,  3.47576644e-01,  3.67984807e-01,\n",
       "         3.88392970e-01,  4.08801133e-01,  4.29209297e-01,\n",
       "         4.49617460e-01,  4.70025623e-01,  4.90433786e-01,\n",
       "         5.10841950e-01,  5.31250113e-01,  5.51658276e-01,\n",
       "         5.72066440e-01,  5.92474603e-01,  6.12882766e-01,\n",
       "         6.33290929e-01,  6.53699093e-01,  6.74107256e-01,\n",
       "         6.94515419e-01,  7.14923582e-01],\n",
       "       [-1.15126443e-01, -9.47182793e-02, -7.43101160e-02,\n",
       "        -5.39019527e-02, -3.34937895e-02, -1.30856262e-02,\n",
       "         7.32253707e-03,  2.77307003e-02,  4.81388636e-02,\n",
       "         6.85470269e-02,  8.89551901e-02,  1.09363353e-01,\n",
       "         1.29771517e-01,  1.50179680e-01,  1.70587843e-01,\n",
       "         1.90996006e-01,  2.11404170e-01,  2.31812333e-01,\n",
       "         2.52220496e-01,  2.72628660e-01,  2.93036823e-01,\n",
       "         3.13444986e-01,  3.33853149e-01,  3.54261313e-01,\n",
       "         3.74669476e-01,  3.95077639e-01,  4.15485802e-01,\n",
       "         4.35893966e-01,  4.56302129e-01,  4.76710292e-01,\n",
       "         4.97118455e-01,  5.17526619e-01,  5.37934782e-01,\n",
       "         5.58342945e-01,  5.78751108e-01,  5.99159272e-01,\n",
       "         6.19567435e-01,  6.39975598e-01,  6.60383762e-01,\n",
       "         6.80791925e-01,  7.01200088e-01,  7.21608251e-01,\n",
       "         7.42016415e-01,  7.62424578e-01,  7.82832741e-01,\n",
       "         8.03240904e-01,  8.23649068e-01,  8.44057231e-01,\n",
       "         8.64465394e-01,  8.84873557e-01],\n",
       "       [-8.46163391e-01, -8.25755228e-01, -8.05347064e-01,\n",
       "        -7.84938901e-01, -7.64530738e-01, -7.44122574e-01,\n",
       "        -7.23714411e-01, -7.03306248e-01, -6.82898085e-01,\n",
       "        -6.62489921e-01, -6.42081758e-01, -6.21673595e-01,\n",
       "        -6.01265432e-01, -5.80857268e-01, -5.60449105e-01,\n",
       "        -5.40040942e-01, -5.19632779e-01, -4.99224615e-01,\n",
       "        -4.78816452e-01, -4.58408289e-01, -4.38000126e-01,\n",
       "        -4.17591962e-01, -3.97183799e-01, -3.76775636e-01,\n",
       "        -3.56367472e-01, -3.35959309e-01, -3.15551146e-01,\n",
       "        -2.95142983e-01, -2.74734819e-01, -2.54326656e-01,\n",
       "        -2.33918493e-01, -2.13510330e-01, -1.93102166e-01,\n",
       "        -1.72694003e-01, -1.52285840e-01, -1.31877677e-01,\n",
       "        -1.11469513e-01, -9.10613500e-02, -7.06531867e-02,\n",
       "        -5.02450235e-02, -2.98368602e-02, -9.42869694e-03,\n",
       "         1.09794663e-02,  3.13876296e-02,  5.17957929e-02,\n",
       "         7.22039561e-02,  9.26121194e-02,  1.13020283e-01,\n",
       "         1.33428446e-01,  1.53836609e-01],\n",
       "       [-6.08295020e-02, -4.04213387e-02, -2.00131755e-02,\n",
       "         3.94987788e-04,  2.08031511e-02,  4.12113143e-02,\n",
       "         6.16194776e-02,  8.20276408e-02,  1.02435804e-01,\n",
       "         1.22843967e-01,  1.43252131e-01,  1.63660294e-01,\n",
       "         1.84068457e-01,  2.04476620e-01,  2.24884784e-01,\n",
       "         2.45292947e-01,  2.65701110e-01,  2.86109274e-01,\n",
       "         3.06517437e-01,  3.26925600e-01,  3.47333763e-01,\n",
       "         3.67741927e-01,  3.88150090e-01,  4.08558253e-01,\n",
       "         4.28966416e-01,  4.49374580e-01,  4.69782743e-01,\n",
       "         4.90190906e-01,  5.10599069e-01,  5.31007233e-01,\n",
       "         5.51415396e-01,  5.71823559e-01,  5.92231722e-01,\n",
       "         6.12639886e-01,  6.33048049e-01,  6.53456212e-01,\n",
       "         6.73864376e-01,  6.94272539e-01,  7.14680702e-01,\n",
       "         7.35088865e-01,  7.55497029e-01,  7.75905192e-01,\n",
       "         7.96313355e-01,  8.16721518e-01,  8.37129682e-01,\n",
       "         8.57537845e-01,  8.77946008e-01,  8.98354171e-01,\n",
       "         9.18762335e-01,  9.39170498e-01]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, 1, 50) - np.random.rand(5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 3]],\n",
       "\n",
       "       [[4, 5, 6]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3], [4,5,6]])\n",
    "a[:, np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n"
     ]
    }
   ],
   "source": [
    "a= [1,2,3]\n",
    "b= [4,5,6]\n",
    "zip(a, b)\n",
    "for i, j in zip([1], [1,2,3]):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x160d25a80>\n"
     ]
    }
   ],
   "source": [
    "print(zip([1], [1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x1052eab40>\n"
     ]
    }
   ],
   "source": [
    "print(zip([1], [1,2,3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "ml_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
