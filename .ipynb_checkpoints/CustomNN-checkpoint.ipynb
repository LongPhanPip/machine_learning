{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(X, catagory=None):\n",
    "    if(catagory==None):\n",
    "        catagory = np.unique(X)\n",
    "    ohc = np.zeros((len(X), len(catagory)))\n",
    "    for i in range(len(X)):\n",
    "        t = (catagory == X[i])\n",
    "        pos = np.argmax(t)\n",
    "        ohc[i, pos]  = 1\n",
    "    return ohc, catagory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    c = np.max(X, axis=1, keepdims=True)\n",
    "    exp = np.exp(X - c)\n",
    "    s = np.sum(exp, axis=1, keepdims=True)\n",
    "    return exp / s\n",
    "\n",
    "def relu(X):\n",
    "    return np.maximum(X, 0)\n",
    "\n",
    "def d_relu(X):\n",
    "    return np.where(X > 0, 1, 0)\n",
    "\n",
    "def sigmod(X):\n",
    "    return np.where(X >= 0, 1 / (np.exp(-X) + 1), np.exp(X) / (np.exp(X) + 1))\n",
    "\n",
    "def d_sigmod(X):\n",
    "    return sigmod(X) * (1 - sigmod(X))\n",
    "\n",
    "def d_x(X):\n",
    "    return 1\n",
    "\n",
    "Activation = {'input': None,'relu': relu, 'sigmod': sigmod, 'softmax': softmax}\n",
    "DActivation = {'input': d_x, 'relu': d_relu, 'sigmod': d_sigmod, 'softmax': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    def __init__(self, n, activation='input'):\n",
    "        self.n = n;\n",
    "        self.activation = Activation[activation]\n",
    "        self.dactivation = DActivation[activation]\n",
    "        self.act_name = activation\n",
    "        \n",
    "    def get_n(self):\n",
    "        return self.n\n",
    "    \n",
    "    def get_activation_name(self):\n",
    "        return self.act_name\n",
    "    \n",
    "    def set_value(self, A):\n",
    "        self.A = A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, learning_rate=0.0001):\n",
    "        self.lr = learning_rate\n",
    "        self.layers = []\n",
    "        self.W = []\n",
    "        self.B = []\n",
    "        \n",
    "    def add(self, layer):\n",
    "        if self.layers==[]:\n",
    "            self.layers.append(layer)\n",
    "        else:\n",
    "            w = np.random.randn(self.layers[-1].get_n(), layer.get_n())\n",
    "            b = np.zeros([1, layer.get_n()])\n",
    "            self.W.append(w)\n",
    "            self.B.append(b)\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "    def summary(self):\n",
    "        print('Neural network:')\n",
    "        print(f'Input shape : {0, self.layers[0].get_n()}')\n",
    "        for i in range(1, len(self.layers) - 1):\n",
    "            print(f'Layer {i} : shape : (0, {self.layers[i].get_n()}), params : {self.W[i - 1].size + self.B[i - 1].size}, activation=\"{self.layers[i].get_activation_name()}\"')\n",
    "        \n",
    "        print(f'Output shape : {0, self.layers[-1].get_n()}, activation = \"{self.layers[-1].get_activation_name()}\"')\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.layers[0].set_value(X)\n",
    "        for i in range(0, len(self.W)):\n",
    "            Z = self.layers[i].A.dot(self.W[i]) + self.B[i]\n",
    "            a = self.layers[i + 1].activation(Z)\n",
    "            self.layers[i + 1].set_value(a)    \n",
    "    \n",
    "    def loss(self, X, y):\n",
    "        self.forward(X)\n",
    "        return -np.sum(np.log(self.layers[-1].A[np.arange(len(X)), y]))\n",
    "        \n",
    "    def back_prop(self, y):\n",
    "        dW = []\n",
    "        dB = []\n",
    "               \n",
    "        dZ = self.layers[-1].A - y\n",
    "        \n",
    "        for i in reversed(range(0, len(self.W))):\n",
    "            \n",
    "            dw = self.layers[i].A.T.dot(dZ)\n",
    "            dW.append(dw)\n",
    "            \n",
    "            db = np.sum(dZ, axis=0, keepdims=True)\n",
    "            dB.append(db)\n",
    "            \n",
    "            dA = (dZ).dot(self.W[i].T)\n",
    "            \n",
    "            dZ = dA * self.layers[i].dactivation(self.layers[i].A)\n",
    "            \n",
    "            \n",
    "        return dW, dB\n",
    "    \n",
    "    def update(self, dW, dB):\n",
    "        for i in range(len(self.W)):\n",
    "            self.W[i] -= self.lr * dW[i]\n",
    "            self.B[i] -= self.lr * dB[i]\n",
    "    \n",
    "    def fit(self, X, y, epochs, batch_size=1, validation_data=None):\n",
    "        if len(self.layers) < 2:\n",
    "            print(\"Haven't create at least 2 layers for model\")\n",
    "        else:\n",
    "            m = len(y)\n",
    "            ohc_y, catal = one_hot_encoder(y)\n",
    "            batch_num = int(np.ceil(len(y) / batch_size))\n",
    "            \n",
    "            for i in range(epochs):\n",
    "                print(f'Epoch : {i + 1} / {epochs}')\n",
    "                print('[', end='')\n",
    "                num = 1\n",
    "                for j in range(batch_num):\n",
    "                    while (j / batch_num) / num >= 0.05:\n",
    "                        num += 1\n",
    "                        print('-', end='')\n",
    "                    \n",
    "                    index = np.random.randint(batch_num)\n",
    "                    \n",
    "                    start = index * batch_size\n",
    "                    end = (index + 1) * batch_size\n",
    "                    \n",
    "                    X_t = X[start : end]\n",
    "                    y_t = ohc_y[start : end]\n",
    "\n",
    "                    self.forward(X_t)\n",
    "                    dW, dB = self.back_prop(y_t)\n",
    "                    self.update(dW[::-1], dB[::-1])\n",
    "                    \n",
    "                print(']')\n",
    "\n",
    "    def predict(self, X, return_prob=False):\n",
    "        self.forward(X)\n",
    "        prob = self.layers[-1].A\n",
    "        if(return_prob==False):\n",
    "            return np.argmax(prob, axis=1)\n",
    "        else:\n",
    "            return np.argmax(prob, axis=1), prob\n",
    "        return Z\n",
    "    \n",
    "    def valuate(self, X, y):\n",
    "        pred, prob = self.predict(X, return_prob=True)\n",
    "        accuracy = np.sum((y == pred)) / len(y)\n",
    "        return accuracy, y == pred\n",
    "    \n",
    "    def save(self, filename):\n",
    "        data = {}\n",
    "        i = 1\n",
    "        for layer in self.layers:\n",
    "            data['layer' + str(i)] = {'neurons' : layer.get_n(), 'activation' : layer.get_activation_name()}\n",
    "            i += 1\n",
    "        \n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('data.csv', index_col=0).head(5000).to_numpy()/255\n",
    "y = pd.read_csv('target.csv', index_col=0)['target'].head(5000).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Layer(400))\n",
    "model.add(Layer(300, activation='relu'))\n",
    "model.add(Layer(100, activation='relu'))\n",
    "model.add(Layer(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network:\n",
      "Input shape : (0, 400)\n",
      "Layer 1 : shape : (0, 300), params : 120300, activation=\"relu\"\n",
      "Layer 2 : shape : (0, 100), params : 30100, activation=\"relu\"\n",
      "Output shape : (0, 10), activation = \"softmax\"\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 / 10\n",
      "[-------------------]\n",
      "Epoch : 2 / 10\n",
      "[-------------------]\n",
      "Epoch : 3 / 10\n",
      "[-------------------]\n",
      "Epoch : 4 / 10\n",
      "[-------------------]\n",
      "Epoch : 5 / 10\n",
      "[-------------------]\n",
      "Epoch : 6 / 10\n",
      "[-------------------]\n",
      "Epoch : 7 / 10\n",
      "[-------------------]\n",
      "Epoch : 8 / 10\n",
      "[-------------------]\n",
      "Epoch : 9 / 10\n",
      "[-------------------]\n",
      "Epoch : 10 / 10\n",
      "[-------------------]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X[:1000], y[:1000], epochs=10, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.682"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac, p = model.valuate(X[4000:], y[4000:])\n",
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[408])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1051b6b20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[408].reshape(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26894142, 0.98201379, 0.11920292],\n",
       "       [0.99752738, 0.99330715, 0.88079708]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[-1, 4, -2],[ 6, 5, 2]])\n",
    "sigmod(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 1 column 204 (char 203)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c9e08bd6a519>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extra data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 1 column 204 (char 203)"
     ]
    }
   ],
   "source": [
    "with open('test.json', 'r') as f:\n",
    "    t = json.loads(f.read())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "ml_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
