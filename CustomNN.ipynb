{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(X, catagory=None):\n",
    "    if(catagory==None):\n",
    "        catagory = np.unique(X)\n",
    "    ohc = np.zeros((len(X), len(catagory)))\n",
    "    for i in range(len(X)):\n",
    "        t = (catagory == X[i])\n",
    "        pos = np.argmax(t)\n",
    "        ohc[i, pos]  = 1\n",
    "    return ohc, catagory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    c = np.max(X, axis=1, keepdims=True)\n",
    "    exp = np.exp(X - c)\n",
    "    s = np.sum(exp, axis=1, keepdims=True)\n",
    "    return exp / s\n",
    "\n",
    "def relu(X):\n",
    "    return np.maximum(X, 0)\n",
    "\n",
    "def d_relu(X):\n",
    "    return np.where(X > 0, 1, 0)\n",
    "\n",
    "def sigmod(X):\n",
    "    X = X.astype(np.float128)\n",
    "    return np.where(X > 0, 1 / (np.exp(-X) + 1), np.exp(X) / (np.exp(X) + 1))\n",
    "\n",
    "def d_sigmod(X):\n",
    "    return sigmod(X) * (1 - sigmod(X))\n",
    "\n",
    "def d_x(X):\n",
    "    return 1\n",
    "\n",
    "def tanh(X):\n",
    "    return np.where(X > 0, (np.exp(2*X) + 1) / (np.exp(2*X) - 1), (np.exp(X) - np.exp(-X)) / (np.exp(X) + np.exp(-X))) \n",
    "\n",
    "def d_tanh(X):\n",
    "    return 1 - np.square(tanh(X))\n",
    "\n",
    "Activation = {'input': None,'relu': relu, 'sigmod': sigmod, 'tanh': tanh, 'softmax': softmax}\n",
    "DActivation = {'input': d_x, 'relu': d_relu, 'sigmod': d_sigmod,'tanh': d_tanh,  'softmax': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    def __init__(self, n, activation='input'):\n",
    "        self.n = n;\n",
    "        self.activation = Activation[activation]\n",
    "        self.dactivation = DActivation[activation]\n",
    "        self.act_name = activation\n",
    "        \n",
    "    def get_n(self):\n",
    "        return self.n\n",
    "    \n",
    "    def get_activation_name(self):\n",
    "        return self.act_name\n",
    "    \n",
    "    def set_value(self, A):\n",
    "        self.A = A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, learning_rate=0.0001):\n",
    "        self.lr = learning_rate\n",
    "        self.layers = []\n",
    "        self.W = []\n",
    "        self.B = []\n",
    "\n",
    "    def add(self, layer):\n",
    "        if self.layers == []:\n",
    "            self.layers.append(layer)\n",
    "        else:\n",
    "            w = np.random.randn(self.layers[-1].get_n(), layer.get_n())\n",
    "            b = np.zeros([1, layer.get_n()])\n",
    "            self.W.append(w)\n",
    "            self.B.append(b)\n",
    "            self.layers.append(layer)\n",
    "\n",
    "    def load(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def summary(self):\n",
    "        print('Neural network:')\n",
    "        print(f'Input shape : {0, self.layers[0].get_n()}')\n",
    "        for i in range(1, len(self.layers) - 1):\n",
    "            print(f'Layer {i} : shape : (0, {self.layers[i].get_n()}), params : {self.W[i - 1].size + self.B[i - 1].size}, activation=\"{self.layers[i].get_activation_name()}\"')\n",
    "\n",
    "        print(f'Output shape : {0, self.layers[-1].get_n()}, activation = \"{self.layers[-1].get_activation_name()}\"')\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.layers[0].set_value(X)\n",
    "        for i in range(0, len(self.W)):\n",
    "            Z = self.layers[i].A.dot(self.W[i]) + self.B[i]\n",
    "            a = self.layers[i + 1].activation(Z)\n",
    "            self.layers[i + 1].set_value(a)\n",
    "\n",
    "    def loss(self, X, y):\n",
    "        self.forward(X)\n",
    "        res = -np.log(self.layers[-1].A[np.arange(len(X)), y])\n",
    "        return np.sum(res)\n",
    "\n",
    "    def back_prop(self, y):\n",
    "        dW = []\n",
    "        dB = []\n",
    "\n",
    "        dZ = self.layers[-1].A - y\n",
    "\n",
    "        for i in reversed(range(0, len(self.W))):\n",
    "\n",
    "            dw = self.layers[i].A.T.dot(dZ)\n",
    "            dW.append(dw)\n",
    "\n",
    "            db = np.sum(dZ, axis=0, keepdims=True)\n",
    "            dB.append(db)\n",
    "\n",
    "            dA = (dZ).dot(self.W[i].T)\n",
    "\n",
    "            dZ = dA * self.layers[i].dactivation(self.layers[i].A)\n",
    "\n",
    "        return dW, dB\n",
    "\n",
    "    def update(self, dW, dB):\n",
    "        for i in range(len(self.W)):\n",
    "            self.W[i] -= self.lr * dW[i]\n",
    "            self.B[i] -= self.lr * dB[i]\n",
    "\n",
    "    def fit(self, X, y, epochs, batch_size=1, validation_data=None):\n",
    "        self.train = []\n",
    "        self.val = []\n",
    "\n",
    "        if len(self.layers) < 2:\n",
    "            print(\"Haven't create at least 2 layers for model\")\n",
    "        else:\n",
    "            m = len(y)\n",
    "            ohc_y, catal = one_hot_encoder(y)\n",
    "            batch_num = int(np.ceil(len(y) / batch_size))\n",
    "\n",
    "            for i in range(epochs):\n",
    "                print(f'Epoch : {i + 1} / {epochs}')\n",
    "                print('[', end='')\n",
    "                num = 1\n",
    "                for j in range(batch_num):\n",
    "                    while (j / batch_num) / num >= 0.025:\n",
    "                        num += 1\n",
    "                        print('-', end='')\n",
    "\n",
    "                    index = np.random.randint(batch_num)\n",
    "\n",
    "                    start = index * batch_size\n",
    "                    end = (index + 1) * batch_size\n",
    "\n",
    "                    X_t = X[start: end]\n",
    "                    y_t = ohc_y[start: end]\n",
    "\n",
    "                    self.forward(X_t)\n",
    "                    dW, dB = self.back_prop(y_t)\n",
    "                    self.update(dW[::-1], dB[::-1])\n",
    "\n",
    "                print(']', end=' ')\n",
    "\n",
    "                train_acc = self.valuate(X, y)\n",
    "                self.train.append(train_acc)\n",
    "                if (validation_data != None):\n",
    "                    val_acc = self.valuate(validation_data[0], validation_data[1])\n",
    "                    self.val.append(val_acc)\n",
    "                    print(f'train_accuracy: {self.train[-1]} | val_accuracy: {self.val[-1]}')\n",
    "\n",
    "                else:\n",
    "                    print(f'loss_train: {self.train[-1]}')\n",
    "\n",
    "    def plot(self):\n",
    "        plt.style.use('seaborn-whitegrid')\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.plot(self.train, c='orange', label='Training')\n",
    "        plt.plot(self.val, c='red', label='Valuation')\n",
    "        plt.legend(loc='best', fontsize=16)\n",
    "        plt.xlabel(\"Epochs\", fontsize=12)\n",
    "        plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "        plt.show()\n",
    "\n",
    "    def predict(self, X, return_prob=False):\n",
    "        self.forward(X)\n",
    "        prob = self.layers[-1].A\n",
    "        if(return_prob == False):\n",
    "            return np.argmax(prob, axis=1)\n",
    "        else:\n",
    "            return np.argmax(prob, axis=1), prob\n",
    "        return Z\n",
    "\n",
    "    def valuate(self, X, y):\n",
    "        pred, prob = self.predict(X, return_prob=True)\n",
    "        accuracy = np.sum((y == pred)) / len(y)\n",
    "        return accuracy\n",
    "\n",
    "    def save(self, filename):\n",
    "        name, ext = filename.split('.')\n",
    "        data = {'lr': self.lr}\n",
    "        layer = {}\n",
    "        i = 0\n",
    "        for l in self.layers:\n",
    "            layer['l' + str(i)] = {'neurons': l.get_n(), 'activation': l.get_activation_name()}\n",
    "            i += 1\n",
    "        data['layer'] = layer\n",
    "\n",
    "        with open(name + '.npy', 'wb') as f:\n",
    "            for w in self.W:\n",
    "                np.save(f, w)\n",
    "            for b in self.B:\n",
    "                np.save(f, b)\n",
    "\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(data, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filename):\n",
    "    name, ext = filename.split('.')\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        model = NeuralNetwork(data['lr'])\n",
    "        layers = data['layer']\n",
    "        for id, layer in layers.items():\n",
    "            model.load(Layer(layer['neurons'], activation=layer['activation']))\n",
    "        \n",
    "    with open(name + '.npy', 'rb') as f:\n",
    "        for i in range(len(layers) - 1):\n",
    "                w = np.load(f)\n",
    "                model.W.append(w)\n",
    "                \n",
    "        for i in range(len(layers) - 1):\n",
    "                b = np.load(f)\n",
    "                model.B.append(b)\n",
    "                \n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(learning_rate=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.read_csv('data (Hai).csv', index_col=0).to_numpy()/255\n",
    "y1 = pd.read_csv('target (Hai).csv', index_col=0)['target'].to_numpy()\n",
    "X2 = pd.read_csv('data (Long Pika).csv', index_col=0).to_numpy()/255\n",
    "y2 = pd.read_csv('target (Long Pika).csv', index_col=0)['target'].to_numpy()\n",
    "X3 = pd.read_csv('data (Duc).csv', index_col=0).to_numpy()/255\n",
    "y3 = pd.read_csv('target (Duc).csv', index_col=0)['target'].to_numpy()\n",
    "X = np.r_[X1, X2, X3]\n",
    "y = np.r_[y1, y2, y3]\n",
    "index = np.random.permutation(len(X) - 1)\n",
    "X = X[index]\n",
    "y = y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Layer(400))\n",
    "model.add(Layer(300, activation='relu'))\n",
    "model.add(Layer(200, activation='relu'))\n",
    "model.add(Layer(100, activation='relu'))\n",
    "model.add(Layer(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network:\n",
      "Input shape : (0, 400)\n",
      "Layer 1 : shape : (0, 300), params : 120300, activation=\"relu\"\n",
      "Layer 2 : shape : (0, 200), params : 60200, activation=\"relu\"\n",
      "Layer 3 : shape : (0, 100), params : 20100, activation=\"relu\"\n",
      "Output shape : (0, 10), activation = \"softmax\"\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 / 20\n",
      "[---------------------------------------] train_accuracy: 0.79475 | val_accuracy: 0.7930749128919861\n",
      "Epoch : 2 / 20\n",
      "[---------------------------------------] train_accuracy: 0.84535 | val_accuracy: 0.8429878048780488\n",
      "Epoch : 3 / 20\n",
      "[---------------------------------------] train_accuracy: 0.866575 | val_accuracy: 0.8630226480836237\n",
      "Epoch : 4 / 20\n",
      "[---------------------------------------] train_accuracy: 0.8881 | val_accuracy: 0.8829703832752613\n",
      "Epoch : 5 / 20\n",
      "[---------------------------------------] train_accuracy: 0.89625 | val_accuracy: 0.8927700348432056\n",
      "Epoch : 6 / 20\n",
      "[---------------------------------------] train_accuracy: 0.9106 | val_accuracy: 0.904006968641115\n",
      "Epoch : 7 / 20\n",
      "[---------------------------------------] train_accuracy: 0.912975 | val_accuracy: 0.9072735191637631\n",
      "Epoch : 8 / 20\n",
      "[---------------------------------------] train_accuracy: 0.91965 | val_accuracy: 0.9128484320557492\n",
      "Epoch : 9 / 20\n",
      "[---------------------------------------] train_accuracy: 0.92375 | val_accuracy: 0.9162020905923345\n",
      "Epoch : 10 / 20\n",
      "[---------------------------------------] train_accuracy: 0.921975 | val_accuracy: 0.9156794425087108\n",
      "Epoch : 11 / 20\n",
      "[---------------------------------------] train_accuracy: 0.929325 | val_accuracy: 0.9207752613240419\n",
      "Epoch : 12 / 20\n",
      "[---------------------------------------] train_accuracy: 0.93445 | val_accuracy: 0.926088850174216\n",
      "Epoch : 13 / 20\n",
      "[---------------------------------------] train_accuracy: 0.934 | val_accuracy: 0.9250435540069687\n",
      "Epoch : 14 / 20\n",
      "[---------------------------------------] train_accuracy: 0.938975 | val_accuracy: 0.9286149825783973\n",
      "Epoch : 15 / 20\n",
      "[---------------------------------------] train_accuracy: 0.940975 | val_accuracy: 0.9317508710801393\n",
      "Epoch : 16 / 20\n",
      "[---------------------------------------] train_accuracy: 0.942025 | val_accuracy: 0.9313588850174216\n",
      "Epoch : 17 / 20\n",
      "[---------------------------------------] train_accuracy: 0.945375 | val_accuracy: 0.9314459930313589\n",
      "Epoch : 18 / 20\n",
      "[---------------------------------------] train_accuracy: 0.947125 | val_accuracy: 0.9341898954703832\n",
      "Epoch : 19 / 20\n",
      "[---------------------------------------] train_accuracy: 0.9469 | val_accuracy: 0.9360191637630662\n",
      "Epoch : 20 / 20\n",
      "[---------------------------------------] train_accuracy: 0.946675 | val_accuracy: 0.9333188153310105\n"
     ]
    }
   ],
   "source": [
    "model.fit(X[:40000], y[:40000], epochs=20, batch_size=1, validation_data=(X[40000:], y[40000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = model.valuate(X[4000:], y[4000:])\n",
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X[37437])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(X[37437].reshape(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.predict(X[408])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4]).reshape(1, -1)\n",
    "b = np.array([6,4,5,6]).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.r_[a, b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(model.predict(X[2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(7) + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "ml_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
